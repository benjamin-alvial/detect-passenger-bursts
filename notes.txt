---> Espacio de trabajo
LFS /data/2024/uhadoop/projects/group_22
HDFS /uhadoop2024/projects/group_22

---> Para subir la data
Option 1: download locally and transfer via SCP
Option 2: download directly to cluster-01 with curl or wget; transfer to HDFS; delete from cluster-01 ***

---> Data utilizada en https://www.dtpm.cl/index.php/documentos/matrices-de-viaje
Abril (días 17, 18, 19, 20, 21, 22 y 23)
Tablas de Subidas y Bajadas
Tabla de Viajes (.csv) y Estructura de Tabla de Viajes (.txt)
Tabla de Etapas (.csv)  y Estructura de Tabla de Etapas (.txt) ***

---> Enlace de archivo escogido (etapas)
https://www.dtpm.cl/descargas/modelos_y_matrices/etapas_042023_17al23_transparencia.zip

---> Recomendaciones profe
Comprimir con bzip2
Use replication factor 1 if file is big
hdfs dfs -D dfs.replication=1 -copyFromLocal bigfile.tsv /uhadoop2024/projects/mygroup/
Usar samples

============================================

---> Conectarse a servidor
...

---> Crear directorio en LFS
cd projects
mkdir group_22

---> Descargar con wget
wget https://www.dtpm.cl/descargas/modelos_y_matrices/etapas_042023_17al23_transparencia.zip -O etapas_full.zip

---> Descomprimir, resultado se llama etapas_042023_17al23.csv
unzip etapas_full.zip

---> Usar bzip2 para comprimir de nuevo, esta vez a un bz
bzip2 etapas_042023_17al23.csv

---> Renombrar
mv etapas_042023_17al23.csv.bz2 full.csv.bz2

---> Copiar al HDFS
hdfs dfs -D dfs.replication=1 -copyFromLocal full.csv.bz2 /uhadoop2024/projects/group_22/

---> Revisar que está copiado
hdfs dfs -ls /uhadoop2024/projects/group_22

============================================

Resumen lab 6.

TwitterSimulator -> producer on TOPIC
java -jar mdp-kafka.jar TwitterSimulator [DATA] [TOPIC] 1000

PrintEarthquakeTweets -> consumer of TOPIC
java -jar mdp-kafka.jar PrintEarthquakeTweets [TOPIC]

EarthquakeFilter -> consumer of TOPIC1, producer on TOPIC2
java -jar mdp-kafka.jar EarthquakeFilter [TOPIC1] [TOPIC2]

BurstDetector -> consumer of TOPIC
java -jar mdp-kafka.jar BurstDetector [TOPIC]

Crear topic
kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic [NAME]

Eliminar topic
kafka-topics.sh --delete --zookeeper localhost:2181 --topic [NAME]

============================================

Comandos para correr proyecto.

Copiar .jar a servidor (LFS), desde terminal local
scp -P 220 C:\Users\benja\Desktop\detect-passenger-bursts\mdp-kafka\dist\mdp-kafka.jar uhadoop@cm.dcc.uchile.cl:/data/2024/uhadoop/projects/group_22/kafka

Crear topic
kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic boardings

Correr el .jar (NO FUNCIONA DIRECTO CON DATA EN HDFS)
java -jar mdp-kafka.jar TwitterSimulator hdfs://cm:9000/uhadoop2024/projects/group_22/codeswap/out6/part-r-00000 boardings 1000
java -jar mdp-kafka.jar PrintEarthquakeTweets boardings

OTRA OPCIÓN: COPIAR AL LFS EN CARPETA TESTING...
hdfs dfs -get /uhadoop2024/projects/group_22/codeswap/out6/part-r-00000 /data/2024/uhadoop/projects/group_22/testing
java -jar mdp-kafka.jar TwitterSimulator /data/2024/uhadoop/projects/group_22/testing/part-r-00000 boardings 1000
java -jar mdp-kafka.jar PrintEarthquakeTweets boardings

--------------------------------------------

Crear topic
kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic boardings-filtered

Correr el .jar
java -jar mdp-kafka.jar BurstDetector boardings-filtered
java -jar mdp-kafka.jar EarthquakeFilter boardings boardings-filtered
java -jar mdp-kafka.jar TwitterSimulator /data/2024/uhadoop/projects/group_22/testing/part-r-00000 boardings 1000

============================================

Extra

zcat /data/uhadoop/shared/twitter/tweets_20170919.tsv.gz | more
2017-09-19 00:00:00     2012-09-07 02:26:19     243897957391429632      801852456       RT_ROOT en      Tha
t awkward moment when u are at the skatepark scootering and the only people there are skaters smoking weed.
 #scootscoot #skootkrew #meow   2
2017-09-19 00:00:00     2017-09-14 02:20:01     908153333185236992      1518087734      RT_ROOT en      If
the police say "Hang tight "your ass is going to jail ? 1274
...

hdfs dfs -cat /uhadoop2024/projects/group_22/codeswap/out6/part-r-00000 | more
PB1690  2023-04-17 05:29:25.000
PG1666  2023-04-17 05:46:19.000
PB1060  2023-04-17 05:48:44.000
PF759   2023-04-17 05:49:14.000
...

============================================


Group number: 22

Project title: Detecting bursts of boarding passengers in bus routes

Data used: Matrices de Viaje dataset available here, contains information about trips on public transport in Santiago, Chile, including boarding and alight locations and timestamps in 10.824.610 rows and 100 columns (There is a lot more information).

Technology used: Kafka.

Main objective: We are planning to simulate a stream of the data from where we can detect bursts of people boarding on a specific train station. Concretely, we want to analyze the 506 bus route (still deciding if we will use specifically this bus route) to detect the location and time of the top x bursts of people entering the system per day. This would be useful to support decisions about transport demand planning.
